{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMsNxJ84A/9LC2rTpDOJ8ht",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BhimPrasadAdhikari/my-first-llm/blob/main/my-llm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --no-check-certificate \\\n",
        "  https://storage.googleapis.com/learning_datasets/glove.zip \\\n",
        "  -O /tmp/glove.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mg8xx4CY6gJ8",
        "outputId": "3c7dc69c-e8ed-479e-de67-53c34061961b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-05 17:26:26--  https://storage.googleapis.com/learning_datasets/glove.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.2.207, 142.250.141.207, 74.125.137.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.2.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-09-05 17:26:27 ERROR 404: Not Found.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYkbrpxikwqM"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tf_keras import Sequential, datasets\n",
        "from tf_keras.layers import Dense, Flatten"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_label) = data.load_data()"
      ],
      "metadata": {
        "id": "eaVhTLkPmOlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalizing images to 0 & 1 pixel value\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "JiojLaoftMy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_images = training_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "metadata": {
        "id": "UDF6VoWPm0L9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Flatten(input_shape=(28,28)),\n",
        "    Dense(128, activation=tf.nn.relu),\n",
        "    Dense(10, activation=tf.nn.softmax)\n",
        "])"
      ],
      "metadata": {
        "id": "gBmXxqgUtbQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. First layer is the input layer. 28*28 1.pixels are arranged in a single array ie flatten to 1-D.\n",
        "\n",
        "2. Second layer is the dense layer consisting of 128 neurons ie each pixel is connected to each neuron(many to one).\n",
        "  *  uses Rectified Linear Unit(relu) it is f(x)=max(0,x)\n",
        "  * basically it returns value 0 - positive\n",
        "\n",
        "3. Third layer is the output layer. It consists of fully connected 10 neurons.\n",
        "  * uses softmax function as activation\n",
        "  it is f(x)= e^x1 / âˆ‘ e^x(2,3...10)\n",
        "  * 10 neurons spit out the the probalilty and this activation helps to distribute probability to the all 10 numeric values.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "tpxWkZpItz5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "yDrE7WBCuDqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x0NYTSL_8haN",
        "outputId": "dc867396-9a45-4f39-8378-290e6fb76e5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(training_images, training_labels, epochs=5)"
      ],
      "metadata": {
        "id": "6_IsnAZq8Orp",
        "outputId": "3338f247-e7dc-4626-abfd-ac1fda8d2d75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2851 - accuracy: 0.8949\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2709 - accuracy: 0.8999\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2591 - accuracy: 0.9032\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2486 - accuracy: 0.9070\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2410 - accuracy: 0.9102\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf_keras.src.callbacks.History at 0x787f2de95b90>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_images.shape"
      ],
      "metadata": {
        "id": "EU4PVXyw-oXP",
        "outputId": "e1961215-10be-423e-8428-c3cfc96619a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PbH2dE2d-znX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_label.shape"
      ],
      "metadata": {
        "id": "sFb8N8tb_J1D",
        "outputId": "764cd9ce-258e-4880-a324-f47b08c92e53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifications= model.predict(test_images)\n",
        "print(classifications[0])\n",
        "print(test_label[0])"
      ],
      "metadata": {
        "id": "_6yqh7Tk-h_R",
        "outputId": "c18c7ddd-fb72-4998-99f6-0f1e2d9d6225",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 0s 1ms/step\n",
            "[9.7126382e-08 1.0877104e-10 6.4578126e-10 1.0977614e-12 1.7186772e-09\n",
            " 1.5597625e-04 7.2577916e-10 5.5664130e-03 6.5998551e-10 9.9427748e-01]\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutional neural network"
      ],
      "metadata": {
        "id": "_GpV05jZR_KN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tf_keras import datasets, models\n",
        "from tf_keras.layers import Flatten, Dense, Conv2D, MaxPooling2D\n",
        "\n"
      ],
      "metadata": {
        "id": "X5EFFGo_SMJ6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = datasets.fashion_mnist\n",
        "(training_images, training_labels),(test_images, test_labels) = data.load_data()\n",
        "\n",
        "training_images = training_images.reshape(60000,28,28,1)\n",
        "training_images = training_images / 255.0\n",
        "test_images = test_images.reshape(10000,28,28,1)\n",
        "test_images = test_images / 255.0\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIfmx24hTDqR",
        "outputId": "b10d9748-3e9d-4b2b-e96c-0bac60615353"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential([\n",
        "    Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D(2,2),\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "    Flatten(),\n",
        "    Dense(128, activation=tf.nn.relu),\n",
        "    Dense(10, activation=tf.nn.softmax)\n",
        "])"
      ],
      "metadata": {
        "id": "YTXHR22iUtfT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "hC8xwKMROP--"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(training_images, training_labels, epochs=20)"
      ],
      "metadata": {
        "id": "cLylBudnOz8r",
        "outputId": "ac86b135-521e-4bf0-8818-0d2f237fd4a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 86s 45ms/step - loss: 0.4342 - accuracy: 0.8437\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 103s 55ms/step - loss: 0.2908 - accuracy: 0.8939\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 99s 53ms/step - loss: 0.2441 - accuracy: 0.9092\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 85s 45ms/step - loss: 0.2092 - accuracy: 0.9216\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 81s 43ms/step - loss: 0.1845 - accuracy: 0.9308\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 83s 44ms/step - loss: 0.1602 - accuracy: 0.9402\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.1406 - accuracy: 0.9465\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.1219 - accuracy: 0.9535\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.1068 - accuracy: 0.9594\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 82s 44ms/step - loss: 0.0919 - accuracy: 0.9649\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 82s 43ms/step - loss: 0.0809 - accuracy: 0.9701\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.0729 - accuracy: 0.9719\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 84s 45ms/step - loss: 0.0629 - accuracy: 0.9761\n",
            "Epoch 14/20\n",
            "1381/1875 [=====================>........] - ETA: 21s - loss: 0.0594 - accuracy: 0.9776"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_images, test_labels)\n"
      ],
      "metadata": {
        "id": "mg9z32X1PA81",
        "outputId": "748a44a2-29c0-4d09-950d-913d7fddc108",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 3s 11ms/step - loss: 0.2617 - accuracy: 0.9039\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2617473900318146, 0.9039000272750854]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "from tf_keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "url = \"https://storage.googleapis.com/learning-datasets/horse-or-human.zip\"\n",
        "file_name = \"horse-or-human.zip\"\n",
        "training_dir = 'horse-or-human/training/'\n",
        "urllib.request.urlretrieve(url,file_name)\n",
        "\n",
        "zip_ref= zipfile.ZipFile(file_name,'r')\n",
        "zip_ref.extractall(training_dir)\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "EToF3PjbvWww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_url = \"https://storage.googleapis.com/learning-datasets/validation-horse-or-human.zip\"\n",
        "validation_file_name = \"validation-horse-or-human.zip\"\n",
        "validation_dir = 'horse-or-human/validation/'\n",
        "urllib.request.urlretrieve(validation_url, validation_file_name)\n",
        "\n",
        "zip_ref = zipfile.ZipFile(validation_file_name, 'r')\n",
        "zip_ref.extractall(validation_dir)\n",
        "zip_ref.close()\n"
      ],
      "metadata": {
        "id": "6c-025vJveyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing the image data for training using ImageDataGenerator, a real-time data augmentation and preprocessing."
      ],
      "metadata": {
        "id": "_DT5rQa9YrZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tf_keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale=1/255)\n",
        "training_dir = 'horse-or-human/training/'\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    training_dir,\n",
        "    target_size=(300,300),\n",
        "    class_mode='binary'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haIbNUwiWybL",
        "outputId": "81f43298-62fb-40dd-c690-eda9a0e59e5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1027 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tf_keras import models\n",
        "from tf_keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tf_keras.optimizers import RMSprop\n",
        "\n",
        "model = models.Sequential([\n",
        "    Conv2D(16, (3,3), activation='relu',  input_shape=(300,300,3)),\n",
        "    MaxPooling2D(2,2),\n",
        "    Conv2D(32, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=RMSprop(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "To17C8dDaKoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=15\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpgomvPCnVBD",
        "outputId": "980c9a63-3b18-49ef-f97d-e3a11eb3be16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "33/33 [==============================] - 113s 3s/step - loss: 2.3799 - accuracy: 0.5910\n",
            "Epoch 2/15\n",
            "33/33 [==============================] - 112s 3s/step - loss: 0.3252 - accuracy: 0.8676\n",
            "Epoch 3/15\n",
            "33/33 [==============================] - 114s 3s/step - loss: 0.1968 - accuracy: 0.9250\n",
            "Epoch 4/15\n",
            "33/33 [==============================] - 108s 3s/step - loss: 0.1452 - accuracy: 0.9601\n",
            "Epoch 5/15\n",
            "33/33 [==============================] - 110s 3s/step - loss: 0.1773 - accuracy: 0.9669\n",
            "Epoch 6/15\n",
            "33/33 [==============================] - 110s 3s/step - loss: 0.0250 - accuracy: 0.9912\n",
            "Epoch 7/15\n",
            "33/33 [==============================] - 110s 3s/step - loss: 0.0080 - accuracy: 0.9971\n",
            "Epoch 8/15\n",
            "33/33 [==============================] - 109s 3s/step - loss: 0.2096 - accuracy: 0.9620\n",
            "Epoch 9/15\n",
            "33/33 [==============================] - 113s 3s/step - loss: 0.0054 - accuracy: 1.0000\n",
            "Epoch 10/15\n",
            "33/33 [==============================] - 119s 4s/step - loss: 9.4466e-04 - accuracy: 1.0000\n",
            "Epoch 11/15\n",
            "33/33 [==============================] - 111s 3s/step - loss: 0.8051 - accuracy: 0.9679\n",
            "Epoch 12/15\n",
            "33/33 [==============================] - 108s 3s/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 13/15\n",
            "33/33 [==============================] - 109s 3s/step - loss: 4.7823e-04 - accuracy: 1.0000\n",
            "Epoch 14/15\n",
            "33/33 [==============================] - 110s 3s/step - loss: 1.6032e-04 - accuracy: 1.0000\n",
            "Epoch 15/15\n",
            "33/33 [==============================] - 109s 3s/step - loss: 0.3315 - accuracy: 0.9630\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dKOnL6zvbpaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VAs2qMRv3Xg",
        "outputId": "385c291e-97f7-4573-b095-589be7483e79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 298, 298, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 149, 149, 16)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 147, 147, 32)      4640      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 73, 73, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 71, 71, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 35, 35, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 78400)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               40141312  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 40165409 (153.22 MB)\n",
            "Trainable params: 40165409 (153.22 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from tf_keras.preprocessing import image\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  path = '/content/' + fn\n",
        "  img = image.load_img(path, target_size=(300,300))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  image_tensor = np.vstack([x])\n",
        "  classes = model.predict(image_tensor)\n",
        "  print(classes)\n",
        "  print(classes[0])\n",
        "  if(classes[0]>0.5):\n",
        "    print(fn+' is a human')\n",
        "  else:\n",
        "    print(fn+' is a horse')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dOAvLDl1Sd8W",
        "outputId": "86019385-2284-4e67-aa15-7ae1eca8ef57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d3e878e6-f8b0-4b8d-b4e0-a2f7b55b0266\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d3e878e6-f8b0-4b8d-b4e0-a2f7b55b0266\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving selu.jpg to selu (3).jpg\n",
            "1/1 [==============================] - 0s 285ms/step\n",
            "[[1.14262994e-35]]\n",
            "[1.14262994e-35]\n",
            "selu (3).jpg is a horse\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using the open source weights"
      ],
      "metadata": {
        "id": "KnQRd-WuWiQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tf_keras.preprocessing.image import ImageDataGenerator\n",
        "from tf_keras import layers, Model\n",
        "from tf_keras.applications.inception_v3 import InceptionV3\n",
        "from tf_keras.optimizers import RMSprop\n",
        "import urllib\n",
        "\n",
        "weights_url = \"https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
        "weights_file = \"inception_v3.h5\"\n",
        "urllib.request.urlretrieve(weights_url, weights_file)\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape=(150,150,3),\n",
        "                                include_top=False,\n",
        "                                weights=None)\n",
        "\n",
        "pre_trained_model.load_weights(weights_file)\n",
        "\n"
      ],
      "metadata": {
        "id": "IAWoPrB2SWqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre_trained_model.summary()"
      ],
      "metadata": {
        "id": "yX63www3Z1fR",
        "outputId": "31e2425d-6214-4f42-a9f0-5e55686c07ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)        [(None, 150, 150, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d_191 (Conv2D)         (None, 74, 74, 32)           864       ['input_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_188 (B  (None, 74, 74, 32)           96        ['conv2d_191[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_188 (Activation  (None, 74, 74, 32)           0         ['batch_normalization_188[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_192 (Conv2D)         (None, 72, 72, 32)           9216      ['activation_188[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_189 (B  (None, 72, 72, 32)           96        ['conv2d_192[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_189 (Activation  (None, 72, 72, 32)           0         ['batch_normalization_189[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_193 (Conv2D)         (None, 72, 72, 64)           18432     ['activation_189[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_190 (B  (None, 72, 72, 64)           192       ['conv2d_193[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_190 (Activation  (None, 72, 72, 64)           0         ['batch_normalization_190[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " max_pooling2d_11 (MaxPooli  (None, 35, 35, 64)           0         ['activation_190[0][0]']      \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv2d_194 (Conv2D)         (None, 35, 35, 80)           5120      ['max_pooling2d_11[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_191 (B  (None, 35, 35, 80)           240       ['conv2d_194[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_191 (Activation  (None, 35, 35, 80)           0         ['batch_normalization_191[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_195 (Conv2D)         (None, 33, 33, 192)          138240    ['activation_191[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_192 (B  (None, 33, 33, 192)          576       ['conv2d_195[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_192 (Activation  (None, 33, 33, 192)          0         ['batch_normalization_192[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " max_pooling2d_12 (MaxPooli  (None, 16, 16, 192)          0         ['activation_192[0][0]']      \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv2d_199 (Conv2D)         (None, 16, 16, 64)           12288     ['max_pooling2d_12[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_196 (B  (None, 16, 16, 64)           192       ['conv2d_199[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_196 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_196[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_197 (Conv2D)         (None, 16, 16, 48)           9216      ['max_pooling2d_12[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_200 (Conv2D)         (None, 16, 16, 96)           55296     ['activation_196[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_194 (B  (None, 16, 16, 48)           144       ['conv2d_197[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_197 (B  (None, 16, 16, 96)           288       ['conv2d_200[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_194 (Activation  (None, 16, 16, 48)           0         ['batch_normalization_194[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_197 (Activation  (None, 16, 16, 96)           0         ['batch_normalization_197[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_18 (Aver  (None, 16, 16, 192)          0         ['max_pooling2d_12[0][0]']    \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_196 (Conv2D)         (None, 16, 16, 64)           12288     ['max_pooling2d_12[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_198 (Conv2D)         (None, 16, 16, 64)           76800     ['activation_194[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_201 (Conv2D)         (None, 16, 16, 96)           82944     ['activation_197[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_202 (Conv2D)         (None, 16, 16, 32)           6144      ['average_pooling2d_18[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_193 (B  (None, 16, 16, 64)           192       ['conv2d_196[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_195 (B  (None, 16, 16, 64)           192       ['conv2d_198[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_198 (B  (None, 16, 16, 96)           288       ['conv2d_201[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_199 (B  (None, 16, 16, 32)           96        ['conv2d_202[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_193 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_193[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_195 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_195[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_198 (Activation  (None, 16, 16, 96)           0         ['batch_normalization_198[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_199 (Activation  (None, 16, 16, 32)           0         ['batch_normalization_199[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed0 (Concatenate)        (None, 16, 16, 256)          0         ['activation_193[0][0]',      \n",
            "                                                                     'activation_195[0][0]',      \n",
            "                                                                     'activation_198[0][0]',      \n",
            "                                                                     'activation_199[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_206 (Conv2D)         (None, 16, 16, 64)           16384     ['mixed0[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_203 (B  (None, 16, 16, 64)           192       ['conv2d_206[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_203 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_203[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_204 (Conv2D)         (None, 16, 16, 48)           12288     ['mixed0[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_207 (Conv2D)         (None, 16, 16, 96)           55296     ['activation_203[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_201 (B  (None, 16, 16, 48)           144       ['conv2d_204[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_204 (B  (None, 16, 16, 96)           288       ['conv2d_207[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_201 (Activation  (None, 16, 16, 48)           0         ['batch_normalization_201[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_204 (Activation  (None, 16, 16, 96)           0         ['batch_normalization_204[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_19 (Aver  (None, 16, 16, 256)          0         ['mixed0[0][0]']              \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_203 (Conv2D)         (None, 16, 16, 64)           16384     ['mixed0[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_205 (Conv2D)         (None, 16, 16, 64)           76800     ['activation_201[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_208 (Conv2D)         (None, 16, 16, 96)           82944     ['activation_204[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_209 (Conv2D)         (None, 16, 16, 64)           16384     ['average_pooling2d_19[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_200 (B  (None, 16, 16, 64)           192       ['conv2d_203[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_202 (B  (None, 16, 16, 64)           192       ['conv2d_205[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_205 (B  (None, 16, 16, 96)           288       ['conv2d_208[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_206 (B  (None, 16, 16, 64)           192       ['conv2d_209[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_200 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_200[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_202 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_202[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_205 (Activation  (None, 16, 16, 96)           0         ['batch_normalization_205[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_206 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_206[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed1 (Concatenate)        (None, 16, 16, 288)          0         ['activation_200[0][0]',      \n",
            "                                                                     'activation_202[0][0]',      \n",
            "                                                                     'activation_205[0][0]',      \n",
            "                                                                     'activation_206[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_213 (Conv2D)         (None, 16, 16, 64)           18432     ['mixed1[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_210 (B  (None, 16, 16, 64)           192       ['conv2d_213[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_210 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_210[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_211 (Conv2D)         (None, 16, 16, 48)           13824     ['mixed1[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_214 (Conv2D)         (None, 16, 16, 96)           55296     ['activation_210[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_208 (B  (None, 16, 16, 48)           144       ['conv2d_211[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_211 (B  (None, 16, 16, 96)           288       ['conv2d_214[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_208 (Activation  (None, 16, 16, 48)           0         ['batch_normalization_208[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_211 (Activation  (None, 16, 16, 96)           0         ['batch_normalization_211[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_20 (Aver  (None, 16, 16, 288)          0         ['mixed1[0][0]']              \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_210 (Conv2D)         (None, 16, 16, 64)           18432     ['mixed1[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_212 (Conv2D)         (None, 16, 16, 64)           76800     ['activation_208[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_215 (Conv2D)         (None, 16, 16, 96)           82944     ['activation_211[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_216 (Conv2D)         (None, 16, 16, 64)           18432     ['average_pooling2d_20[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_207 (B  (None, 16, 16, 64)           192       ['conv2d_210[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_209 (B  (None, 16, 16, 64)           192       ['conv2d_212[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_212 (B  (None, 16, 16, 96)           288       ['conv2d_215[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_213 (B  (None, 16, 16, 64)           192       ['conv2d_216[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_207 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_207[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_209 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_209[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_212 (Activation  (None, 16, 16, 96)           0         ['batch_normalization_212[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_213 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_213[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed2 (Concatenate)        (None, 16, 16, 288)          0         ['activation_207[0][0]',      \n",
            "                                                                     'activation_209[0][0]',      \n",
            "                                                                     'activation_212[0][0]',      \n",
            "                                                                     'activation_213[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_218 (Conv2D)         (None, 16, 16, 64)           18432     ['mixed2[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_215 (B  (None, 16, 16, 64)           192       ['conv2d_218[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_215 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_215[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_219 (Conv2D)         (None, 16, 16, 96)           55296     ['activation_215[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_216 (B  (None, 16, 16, 96)           288       ['conv2d_219[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_216 (Activation  (None, 16, 16, 96)           0         ['batch_normalization_216[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_217 (Conv2D)         (None, 7, 7, 384)            995328    ['mixed2[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_220 (Conv2D)         (None, 7, 7, 96)             82944     ['activation_216[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_214 (B  (None, 7, 7, 384)            1152      ['conv2d_217[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_217 (B  (None, 7, 7, 96)             288       ['conv2d_220[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_214 (Activation  (None, 7, 7, 384)            0         ['batch_normalization_214[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_217 (Activation  (None, 7, 7, 96)             0         ['batch_normalization_217[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " max_pooling2d_13 (MaxPooli  (None, 7, 7, 288)            0         ['mixed2[0][0]']              \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " mixed3 (Concatenate)        (None, 7, 7, 768)            0         ['activation_214[0][0]',      \n",
            "                                                                     'activation_217[0][0]',      \n",
            "                                                                     'max_pooling2d_13[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_225 (Conv2D)         (None, 7, 7, 128)            98304     ['mixed3[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_222 (B  (None, 7, 7, 128)            384       ['conv2d_225[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_222 (Activation  (None, 7, 7, 128)            0         ['batch_normalization_222[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_226 (Conv2D)         (None, 7, 7, 128)            114688    ['activation_222[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_223 (B  (None, 7, 7, 128)            384       ['conv2d_226[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_223 (Activation  (None, 7, 7, 128)            0         ['batch_normalization_223[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_222 (Conv2D)         (None, 7, 7, 128)            98304     ['mixed3[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_227 (Conv2D)         (None, 7, 7, 128)            114688    ['activation_223[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_219 (B  (None, 7, 7, 128)            384       ['conv2d_222[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_224 (B  (None, 7, 7, 128)            384       ['conv2d_227[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_219 (Activation  (None, 7, 7, 128)            0         ['batch_normalization_219[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_224 (Activation  (None, 7, 7, 128)            0         ['batch_normalization_224[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_223 (Conv2D)         (None, 7, 7, 128)            114688    ['activation_219[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_228 (Conv2D)         (None, 7, 7, 128)            114688    ['activation_224[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_220 (B  (None, 7, 7, 128)            384       ['conv2d_223[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_225 (B  (None, 7, 7, 128)            384       ['conv2d_228[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_220 (Activation  (None, 7, 7, 128)            0         ['batch_normalization_220[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_225 (Activation  (None, 7, 7, 128)            0         ['batch_normalization_225[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_21 (Aver  (None, 7, 7, 768)            0         ['mixed3[0][0]']              \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_221 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed3[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_224 (Conv2D)         (None, 7, 7, 192)            172032    ['activation_220[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_229 (Conv2D)         (None, 7, 7, 192)            172032    ['activation_225[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_230 (Conv2D)         (None, 7, 7, 192)            147456    ['average_pooling2d_21[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_218 (B  (None, 7, 7, 192)            576       ['conv2d_221[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_221 (B  (None, 7, 7, 192)            576       ['conv2d_224[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_226 (B  (None, 7, 7, 192)            576       ['conv2d_229[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_227 (B  (None, 7, 7, 192)            576       ['conv2d_230[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_218 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_218[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_221 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_221[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_226 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_226[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_227 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_227[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed4 (Concatenate)        (None, 7, 7, 768)            0         ['activation_218[0][0]',      \n",
            "                                                                     'activation_221[0][0]',      \n",
            "                                                                     'activation_226[0][0]',      \n",
            "                                                                     'activation_227[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_235 (Conv2D)         (None, 7, 7, 160)            122880    ['mixed4[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_232 (B  (None, 7, 7, 160)            480       ['conv2d_235[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_232 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_232[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_236 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_232[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_233 (B  (None, 7, 7, 160)            480       ['conv2d_236[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_233 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_233[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_232 (Conv2D)         (None, 7, 7, 160)            122880    ['mixed4[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_237 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_233[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_229 (B  (None, 7, 7, 160)            480       ['conv2d_232[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_234 (B  (None, 7, 7, 160)            480       ['conv2d_237[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_229 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_229[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_234 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_234[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_233 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_229[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_238 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_234[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_230 (B  (None, 7, 7, 160)            480       ['conv2d_233[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_235 (B  (None, 7, 7, 160)            480       ['conv2d_238[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_230 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_230[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_235 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_235[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_22 (Aver  (None, 7, 7, 768)            0         ['mixed4[0][0]']              \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_231 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed4[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_234 (Conv2D)         (None, 7, 7, 192)            215040    ['activation_230[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_239 (Conv2D)         (None, 7, 7, 192)            215040    ['activation_235[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_240 (Conv2D)         (None, 7, 7, 192)            147456    ['average_pooling2d_22[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_228 (B  (None, 7, 7, 192)            576       ['conv2d_231[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_231 (B  (None, 7, 7, 192)            576       ['conv2d_234[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_236 (B  (None, 7, 7, 192)            576       ['conv2d_239[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_237 (B  (None, 7, 7, 192)            576       ['conv2d_240[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_228 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_228[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_231 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_231[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_236 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_236[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_237 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_237[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed5 (Concatenate)        (None, 7, 7, 768)            0         ['activation_228[0][0]',      \n",
            "                                                                     'activation_231[0][0]',      \n",
            "                                                                     'activation_236[0][0]',      \n",
            "                                                                     'activation_237[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_245 (Conv2D)         (None, 7, 7, 160)            122880    ['mixed5[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_242 (B  (None, 7, 7, 160)            480       ['conv2d_245[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_242 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_242[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_246 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_242[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_243 (B  (None, 7, 7, 160)            480       ['conv2d_246[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_243 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_243[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_242 (Conv2D)         (None, 7, 7, 160)            122880    ['mixed5[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_247 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_243[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_239 (B  (None, 7, 7, 160)            480       ['conv2d_242[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_244 (B  (None, 7, 7, 160)            480       ['conv2d_247[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_239 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_239[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_244 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_244[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_243 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_239[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_248 (Conv2D)         (None, 7, 7, 160)            179200    ['activation_244[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_240 (B  (None, 7, 7, 160)            480       ['conv2d_243[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_245 (B  (None, 7, 7, 160)            480       ['conv2d_248[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_240 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_240[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_245 (Activation  (None, 7, 7, 160)            0         ['batch_normalization_245[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_23 (Aver  (None, 7, 7, 768)            0         ['mixed5[0][0]']              \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_241 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed5[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_244 (Conv2D)         (None, 7, 7, 192)            215040    ['activation_240[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_249 (Conv2D)         (None, 7, 7, 192)            215040    ['activation_245[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_250 (Conv2D)         (None, 7, 7, 192)            147456    ['average_pooling2d_23[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_238 (B  (None, 7, 7, 192)            576       ['conv2d_241[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_241 (B  (None, 7, 7, 192)            576       ['conv2d_244[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_246 (B  (None, 7, 7, 192)            576       ['conv2d_249[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_247 (B  (None, 7, 7, 192)            576       ['conv2d_250[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_238 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_238[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_241 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_241[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_246 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_246[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_247 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_247[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed6 (Concatenate)        (None, 7, 7, 768)            0         ['activation_238[0][0]',      \n",
            "                                                                     'activation_241[0][0]',      \n",
            "                                                                     'activation_246[0][0]',      \n",
            "                                                                     'activation_247[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_255 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed6[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_252 (B  (None, 7, 7, 192)            576       ['conv2d_255[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_252 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_252[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_256 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_252[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_253 (B  (None, 7, 7, 192)            576       ['conv2d_256[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_253 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_253[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_252 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed6[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_257 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_253[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_249 (B  (None, 7, 7, 192)            576       ['conv2d_252[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_254 (B  (None, 7, 7, 192)            576       ['conv2d_257[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_249 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_249[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_254 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_254[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_253 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_249[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_258 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_254[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_250 (B  (None, 7, 7, 192)            576       ['conv2d_253[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_255 (B  (None, 7, 7, 192)            576       ['conv2d_258[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_250 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_250[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_255 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_255[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_24 (Aver  (None, 7, 7, 768)            0         ['mixed6[0][0]']              \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_251 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed6[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_254 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_250[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_259 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_255[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_260 (Conv2D)         (None, 7, 7, 192)            147456    ['average_pooling2d_24[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_248 (B  (None, 7, 7, 192)            576       ['conv2d_251[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_251 (B  (None, 7, 7, 192)            576       ['conv2d_254[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_256 (B  (None, 7, 7, 192)            576       ['conv2d_259[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_257 (B  (None, 7, 7, 192)            576       ['conv2d_260[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_248 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_248[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_251 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_251[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_256 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_256[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_257 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_257[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed7 (Concatenate)        (None, 7, 7, 768)            0         ['activation_248[0][0]',      \n",
            "                                                                     'activation_251[0][0]',      \n",
            "                                                                     'activation_256[0][0]',      \n",
            "                                                                     'activation_257[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_263 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed7[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_260 (B  (None, 7, 7, 192)            576       ['conv2d_263[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_260 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_260[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_264 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_260[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_261 (B  (None, 7, 7, 192)            576       ['conv2d_264[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_261 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_261[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_261 (Conv2D)         (None, 7, 7, 192)            147456    ['mixed7[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_265 (Conv2D)         (None, 7, 7, 192)            258048    ['activation_261[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_258 (B  (None, 7, 7, 192)            576       ['conv2d_261[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_262 (B  (None, 7, 7, 192)            576       ['conv2d_265[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_258 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_258[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_262 (Activation  (None, 7, 7, 192)            0         ['batch_normalization_262[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_262 (Conv2D)         (None, 3, 3, 320)            552960    ['activation_258[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_266 (Conv2D)         (None, 3, 3, 192)            331776    ['activation_262[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_259 (B  (None, 3, 3, 320)            960       ['conv2d_262[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_263 (B  (None, 3, 3, 192)            576       ['conv2d_266[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_259 (Activation  (None, 3, 3, 320)            0         ['batch_normalization_259[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_263 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_263[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " max_pooling2d_14 (MaxPooli  (None, 3, 3, 768)            0         ['mixed7[0][0]']              \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " mixed8 (Concatenate)        (None, 3, 3, 1280)           0         ['activation_259[0][0]',      \n",
            "                                                                     'activation_263[0][0]',      \n",
            "                                                                     'max_pooling2d_14[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_271 (Conv2D)         (None, 3, 3, 448)            573440    ['mixed8[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_268 (B  (None, 3, 3, 448)            1344      ['conv2d_271[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_268 (Activation  (None, 3, 3, 448)            0         ['batch_normalization_268[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_268 (Conv2D)         (None, 3, 3, 384)            491520    ['mixed8[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_272 (Conv2D)         (None, 3, 3, 384)            1548288   ['activation_268[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_265 (B  (None, 3, 3, 384)            1152      ['conv2d_268[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_269 (B  (None, 3, 3, 384)            1152      ['conv2d_272[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_265 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_265[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_269 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_269[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_269 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_265[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_270 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_265[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_273 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_269[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_274 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_269[0][0]']      \n",
            "                                                                                                  \n",
            " average_pooling2d_25 (Aver  (None, 3, 3, 1280)           0         ['mixed8[0][0]']              \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_267 (Conv2D)         (None, 3, 3, 320)            409600    ['mixed8[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_266 (B  (None, 3, 3, 384)            1152      ['conv2d_269[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_267 (B  (None, 3, 3, 384)            1152      ['conv2d_270[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_270 (B  (None, 3, 3, 384)            1152      ['conv2d_273[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_271 (B  (None, 3, 3, 384)            1152      ['conv2d_274[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " conv2d_275 (Conv2D)         (None, 3, 3, 192)            245760    ['average_pooling2d_25[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_264 (B  (None, 3, 3, 320)            960       ['conv2d_267[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_266 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_266[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_267 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_267[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_270 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_270[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_271 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_271[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " batch_normalization_272 (B  (None, 3, 3, 192)            576       ['conv2d_275[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_264 (Activation  (None, 3, 3, 320)            0         ['batch_normalization_264[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed9_0 (Concatenate)      (None, 3, 3, 768)            0         ['activation_266[0][0]',      \n",
            "                                                                     'activation_267[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate  (None, 3, 3, 768)            0         ['activation_270[0][0]',      \n",
            " )                                                                   'activation_271[0][0]']      \n",
            "                                                                                                  \n",
            " activation_272 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_272[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed9 (Concatenate)        (None, 3, 3, 2048)           0         ['activation_264[0][0]',      \n",
            "                                                                     'mixed9_0[0][0]',            \n",
            "                                                                     'concatenate_4[0][0]',       \n",
            "                                                                     'activation_272[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_280 (Conv2D)         (None, 3, 3, 448)            917504    ['mixed9[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_277 (B  (None, 3, 3, 448)            1344      ['conv2d_280[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_277 (Activation  (None, 3, 3, 448)            0         ['batch_normalization_277[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_277 (Conv2D)         (None, 3, 3, 384)            786432    ['mixed9[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_281 (Conv2D)         (None, 3, 3, 384)            1548288   ['activation_277[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_274 (B  (None, 3, 3, 384)            1152      ['conv2d_277[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_278 (B  (None, 3, 3, 384)            1152      ['conv2d_281[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_274 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_274[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_278 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_278[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_278 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_274[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_279 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_274[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_282 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_278[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_283 (Conv2D)         (None, 3, 3, 384)            442368    ['activation_278[0][0]']      \n",
            "                                                                                                  \n",
            " average_pooling2d_26 (Aver  (None, 3, 3, 2048)           0         ['mixed9[0][0]']              \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_276 (Conv2D)         (None, 3, 3, 320)            655360    ['mixed9[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_275 (B  (None, 3, 3, 384)            1152      ['conv2d_278[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_276 (B  (None, 3, 3, 384)            1152      ['conv2d_279[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_279 (B  (None, 3, 3, 384)            1152      ['conv2d_282[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_280 (B  (None, 3, 3, 384)            1152      ['conv2d_283[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " conv2d_284 (Conv2D)         (None, 3, 3, 192)            393216    ['average_pooling2d_26[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_273 (B  (None, 3, 3, 320)            960       ['conv2d_276[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_275 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_275[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_276 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_276[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_279 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_279[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_280 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_280[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " batch_normalization_281 (B  (None, 3, 3, 192)            576       ['conv2d_284[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_273 (Activation  (None, 3, 3, 320)            0         ['batch_normalization_273[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed9_1 (Concatenate)      (None, 3, 3, 768)            0         ['activation_275[0][0]',      \n",
            "                                                                     'activation_276[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate  (None, 3, 3, 768)            0         ['activation_279[0][0]',      \n",
            " )                                                                   'activation_280[0][0]']      \n",
            "                                                                                                  \n",
            " activation_281 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_281[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed10 (Concatenate)       (None, 3, 3, 2048)           0         ['activation_273[0][0]',      \n",
            "                                                                     'mixed9_1[0][0]',            \n",
            "                                                                     'concatenate_5[0][0]',       \n",
            "                                                                     'activation_281[0][0]']      \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 21802784 (83.17 MB)\n",
            "Trainable params: 21768352 (83.04 MB)\n",
            "Non-trainable params: 34432 (134.50 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "\n",
        "print('last layer output shape:', last_layer.output_shape)\n",
        "\n",
        "last_output = last_layer.output"
      ],
      "metadata": {
        "id": "uUickRbo7nOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the output layer to 1 Dimension\n",
        "\n",
        "from tf_keras.layers import Flatten, Dense\n",
        "\n",
        "x = Flatten(last_output)\n",
        "\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "\n",
        "x = Dense(1, activation='sigmoid')(x)"
      ],
      "metadata": {
        "id": "3Fz2xbr6-iF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_a2ApDMk-_Qg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}